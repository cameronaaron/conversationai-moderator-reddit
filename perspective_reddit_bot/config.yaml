# YAML config file for the Perspective Reddit bot.
#
# This config contains "rules" and "ensembles".
#
#
# Rules have the following fields:
#   name: (optional) name for the rule. Must be unique for the config. If none,
#         given, a name is auto-generated based on the models used.
#   perspective_score: A list of models and the thresholds at which to apply the
#                      rule. If multiple models are listed, then the action only
#                      occurs if all thresholds are met
#   comment_features: (optional) A list of features and values. The features:
#       toplevel_only: boolean feature. If true, rule only applies to top-level
#                      comments (comments directly responding to the original
#                      post).
#   action: The moderation action to apply. 'report' flags for moderators and
#           'noop' does nothing.
#   report_reason: (optional) The reason for the report to provide to
#                             moderators. If no report reason is given, one
#                             will be automatically generated from the
#                             perspective_score field.
#
#
#
# Ensembles have the following fields. The weights are logistic regression
# coefficients derived from an ensemble training process, which isn't included
# in this code base.
#   name: a string. this can be used in rules as a model name.
#   feature_weights: a list of API model names and weights.
#   intercept_weight: a bias weight

#
# The list of valid model names is
# 'TOXICITY',
# 'SEVERE_TOXICITY',
# 'IDENTITY_ATTACK',
# 'INSULT',
# 'PROFANITY',
# 'THREAT',
# 'SEXUALLY_EXPLICIT',
# 'ATTACK_ON_AUTHOR',
# 'ATTACK_ON_COMMENTER',
# 'INCOHERENT',
# 'INFLAMMATORY',
# 'LIKELY_TO_REJECT',
# 'OBSCENE',
# 'SPAM',
# 'UNSUBSTANTIAL'

rules:
  - perspective_score:
      SEVERE_TOXICITY: '> 0.9'
    action: report

  - perspective_score:
      IDENTITY_ATTACK: '> 0.9'
    action: report
    report_reason: 'Perspective Bot detected IDENTITY_ATTACK > 0.9'

  - name: 'direct_reply_unsubstantial'
    perspective_score:
      UNSUBSTANTIAL: '> 0.85'
    comment_features:
      toplevel_only: true
    action: report
    report_reason: 'Perspective Bot UNSUBSTANTIAL > 0.85 for top-level comment'

  - perspective_score:
      nonprofanity_toxicity: '> 0.75'
    action: report
    report_reason: 'Perspective Bot detected nonprofanity_toxicity > 0.75'

  #- perspective_score:
  #    SEXUALLY_EXPLICIT: '> 0.9'
  #    PROFANITY: '< 0.5'
  #  action: report
  #  report_reason: 'Perspective Bot detected a comment with SEXUALLY_EXPLICIT > 0.9 and PROFANITY < 0.5.'


ensembles:
  # TODO(jetpack): i totally just made this up. would be neat to actually try to make this.
  - name: 'nonprofanity_toxicity'
    feature_weights:
      SEVERE_TOXICITY: 0.7
      ATTACK_ON_COMMENTER: 0.5
      IDENTITY_ATTACK: 0.4
      INSULT: 0.3
      SEXUALLY_EXPLICIT: 0.2
      THREAT: 0.1
    intercept_weight: -0.2
